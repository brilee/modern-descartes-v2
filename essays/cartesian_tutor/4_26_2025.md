Startup update 1: Embracing the vibecode
2025/4/26
cartesian_tutor,llms

# Progress update

- Set up and build basic conversation + messages backend on top of Postgres. Using simon willison's LLM wrapper + openrouter for an llm-agnostic interface.
- The idea about AI tutoring for high schoolers, targeted at parents still feels good to me. A secondary market/idea might be in creating diverse, synthetic users for testing; I'm imagining that I can do offline testing of my tutor by having them tutor fake students, and this could be a more broadly relevant business.
- Still chewing on whether to take VC money or not. Relatedly, I found Stripe Atlas as a quick-and-dirty C-corp setup hack. I'll have to incorporate anyway if I want to start billing and grab free startup credits.

Next week, my primary goal is to get a UI up and running where I can quickly vibe-test the feel of my agent against a variety of scenarios (onboarding; problem-anchored solution walkthrough; freeform conceptual deep dive, lecture review based on youtube transcript).

# Vibecoding notes

This week, my primary goal was to get familiar with vibecoding. I mostly played with Claude Code and Cursor and Aider. Some notes on vibecoding:

- Checkpoint frequently. Test frequently (manual or automated, possibly tests written by the LLM itself). Rollback frequently rather than try to figure out where the LLM went wrong.
- Per checkpoint, aim to generate a quantity of code that has <1 bug on average. Need to dynamically calibrate to understand the rate at which LLMs write bugs. Past >1 bug/checkpoint, the bugs interact with each other and make debugging exponentially harder (as per https://www.moderndescartes.com/essays/flake_equation/)
- Vibecode the tests before vibecoding the code; with code-first, the tests tend to be templated on the code, testing the implementation details, whereas if there is no implementation detail yet, the LLM can't copy-paste the code into the test. Sometimes copy-pasted code->test is okay.
- Adding API doc context is built into Cursor/Windsurf and you can also just paste a API docs URL into Claude Code to ask it to fetch and read those docs. See also https://llmstxt.site/ for  token-optimized api doc dumps.
- Trick for dealing with new software/ecosystems you aren't familiar with: ask the LLM to generate an "onboarding doc for new engineers" and then run the code it gives you.

# Competitor watch

Found a bunch of "homework answering" services priced at ~$10/month, incl. KhanAmigo from Khan academy (?? what are they doing with their brand??). Not worried about these. I am most impressed with youlearn.ai which seems to have built something close to the MVP I am aiming to build. youlearn is a YC company with 3 cofounders, ~1 million users, ~1-2M ARR (estimated) after 1.5 years of existence. They aim at college students and postsecondary tutoring, with tiktok https://playkit.beehiiv.com/p/youlearn-ai  (!! geez i'm old) as their primary viral marketing channel. They are now reasonably established, and they also have an affiliate program set up. They seem to be hiring to expand into the mobile app market.

The lesson to take away from YouLearn might be that instead of targeting parents, targeting students leads to cheaper, viral growth since students are far more connected on social media.

I got LinkedIn spam inviting me to contribute chemistry expertise to https://outlier.ai/experts/chemistry for $50/hour. (lol)

https://huggingface.co/datasets/nvidia/OpenMathInstruct-2 and others have synthetically generated problem datasets for math. Unclear what competitive advantage I would have if I developed a proprietary synthetic problem pipeline.